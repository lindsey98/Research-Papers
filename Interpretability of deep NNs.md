# Interpretability of deep NNs

## simpler model to explain complex models

## attribution methods

### perturbation-based forward propagation approaches

- Aditya Chattopadhyay and Piyushi Manupriya and Anirban Sarkar and Vineeth N Balasubramanian. **Neural Network Attributions: A Causal Perspective**, 2019. [[paper](https://arxiv.org/abs/1902.02302)]

### backpropagation-based approaches

- Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. **Deep inside convolutional networks: Visualisingimage classification models and saliency maps**, 2014. [[paper](https://arxiv.org/pdf/1312.6034.pdf)]

  *gradient, calculate the gradient with respect to a output at a given input*

- **Visualizing and Understanding Convolutional Networks**.[[paper](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53)]

  *deconvNet*

- Mukund Sundararajan and Ankur Taly and Qiqi Yan. **Gradients of Counterfactuals**, 2016. [[paper](https://arxiv.org/abs/1611.02639)]

- Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, andDhruv Batra.  **Grad-cam:  Visual explanations from deep networks via gradient-based localization.**  InProceedings of the IEEE International Conference on Computer Vision (ICCV), Oct 2017. [[paper](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html)]

- grad cam++

- Pieter-Jan Kindermans and Sara Hooker and Julius Adebayo and Maximilian Alber and Kristof T. Schütt and Sven Dähne and Dumitru Erhan and Been Kim. **The (Un)reliability of saliency methods**, 2017. [[paper](https://arxiv.org/abs/1711.00867)]

- Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. **Learning important features through propagatingactivation differences**, 2019. [[paper](https://arxiv.org/pdf/1704.02685.pdf)]

  *DeepLIFT*

- Mukund Sundararajan, Ankur Taly, and Qiqi Yan. **Axiomatic attribution for deep networks**, 2017. [paper](https://arxiv.org/pdf/1703.01365.pdf) 

## explain models

### example level

- Zijie J. Wang, Robert Turko, Omar Shaikh, Haekyu Park, Nilaksh Das, Fred Hohman, Minsuk Kahng, andDuen Horng Chau. **CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization.** IEEE Transactions on Visualization and Computer Graphics (TVCG), 2020. [[paper](https://arxiv.org/abs/2004.15004)] [[code](https://github.com/poloclub/cnn-explainer)] [[live demo](http://poloclub.github.io/cnn-explainer/)]

### model level

- Hao Yuan, Jiliang Tang, Xia Hu, and Shuiwang Ji. **XGNN: Towards model-level explanations of graph neuralnetworks. ** Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery DataMining, Aug 2020.[[paper](https://arxiv.org/abs/2006.02587)]
- Q. Shen *et al*., **"Visual Interpretation of Recurrent Neural Network on Multi-dimensional Time-series Forecast,**" *2020 IEEE Pacific Visualization Symposium (PacificVis)*, Tianjin, China, 2020, pp. 61-70, doi: 10.1109/PacificVis48177.2020.2785.[[paper](https://ieeexplore.ieee.org/abstract/document/9086238)]











